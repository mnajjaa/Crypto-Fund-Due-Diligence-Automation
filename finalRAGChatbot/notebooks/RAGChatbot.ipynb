{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c208ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain langsmith huggingface_hub transformers sentence-transformers  unstructured tiktoken\n",
    "! pip install pypdf python-docx\n",
    "! pip install -U langchain-community\n",
    "! pip install -q langchain ctransformers\n",
    "! pip install langchain_chroma -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f187f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain core\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.document_loaders import UnstructuredFileLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./notebooks')  # path to reach /websearch/ folder\n",
    "\n",
    "from websearch.test import main\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"./websearch/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "200ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the docs into 110 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "def load_docs(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, file)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file}\")\n",
    "            continue\n",
    "        loader = PyPDFLoader(file_path=pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "folder_path = \"docs\"\n",
    "documents = load_docs(folder_path)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split the docs into {len(splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225ba53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'OpenOffice.org 2.4', 'creator': 'Writer', 'creationdate': '2009-03-24T11:33:15-06:00', 'source': 'docs\\\\bitcoin_whitepaper.pdf', 'total_pages': 9, 'page': 0, 'page_label': '1'}, page_content='Bitcoin: A Peer-to-Peer Electronic Cash System\\nSatoshi Nakamoto\\nsatoshin@gmx.com\\nwww.bitcoin.org\\nAbstract.  A purely peer-to-peer version of  electronic cash would allow online  \\npayments to be sent directly from one party to another without going through a')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "doc_embeds = embeddings.embed_documents([split.page_content for split in splits])\n",
    "doc_embeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fef0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "persist_directory = \"db_rag\"\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag-chatbot\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0759b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-ollama) (0.4.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.52 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-ollama) (0.3.58)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.11.4)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain-ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\onedrive\\documents\\github\\crypto-fund-due-diligence-automation\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BB5F812E40>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-ollama/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BB5F7EB290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-ollama/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BB5F8232C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-ollama/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BB5F8236E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-ollama/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BB5F823DD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-ollama/\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c27c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_local = OllamaLLM(\n",
    "    model=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c3b78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f87b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin (1).pdf', 'total_pages': 9}, page_content='be wary of their customers, hassling them for more information than they would otherwise need.  \\nA certain percentage of fraud is accepted as unavoidable.  These costs and payment uncertainties  \\ncan be avoided in person by using physical currency, but no mechanism exists to make payments'),\n",
       " Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin_whitepaper.pdf', 'total_pages': 9}, page_content='be wary of their customers, hassling them for more information than they would otherwise need.  \\nA certain percentage of fraud is accepted as unavoidable.  These costs and payment uncertainties  \\ncan be avoided in person by using physical currency, but no mechanism exists to make payments'),\n",
       " Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin_whitepaper.pdf', 'total_pages': 9}, page_content='be wary of their customers, hassling them for more information than they would otherwise need.  \\nA certain percentage of fraud is accepted as unavoidable.  These costs and payment uncertainties  \\ncan be avoided in person by using physical currency, but no mechanism exists to make payments')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever.invoke(\"How does Bitcoin prevent fraud?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6920e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    llm=llm_local,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c9a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af888523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Answer the question based only on the following context:\\n[Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 7, 'page_label': '8', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\\\\\bitcoin (1).pdf', 'total_pages': 9}, page_content='the usual framework of coins made from digital signatures, which provides strong control of  \\\\nownership, but is incomplete without a way to prevent double-spending.  To solve this, we  \\\\nproposed a peer-to-peer network using proof-of-work to record a public history of transactions'), Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 7, 'page_label': '8', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\\\\\bitcoin_whitepaper.pdf', 'total_pages': 9}, page_content='the usual framework of coins made from digital signatures, which provides strong control of  \\\\nownership, but is incomplete without a way to prevent double-spending.  To solve this, we  \\\\nproposed a peer-to-peer network using proof-of-work to record a public history of transactions'), Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 7, 'page_label': '8', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\\\\\bitcoin_whitepaper.pdf', 'total_pages': 9}, page_content='the usual framework of coins made from digital signatures, which provides strong control of  \\\\nownership, but is incomplete without a way to prevent double-spending.  To solve this, we  \\\\nproposed a peer-to-peer network using proof-of-work to record a public history of transactions')]\\n\\nQuestion: When was the Bitcoin whitepaper published?\\n\\nAnswer: \", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "\n",
    ")\n",
    "rag_chain.invoke(\"When was the Bitcoin whitepaper published?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3663af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: A Peer-to-Peer Electronic Cash System\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    |llm_local\n",
    ")\n",
    "question = \"What is Bitcoin?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9307c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=response)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2ee4dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Bitcoin?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Bitcoin: A Peer-to-Peer Electronic Cash System', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c195e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the mechanism used by Bitcoin to prevent double-spending, which occurs when a digital coin is spent more than once?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "contextualize_q_system_prompt = (\n",
    "\"Your ONLY task is to reformulate the user’s question so that it can stand alone without the chat history. Do NOT answer it\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_chain = contextualize_q_prompt | llm_local\n",
    "contextualize_chain.invoke({\"input\": \"How does it solve the problem of double spending?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50b1fde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin (1).pdf', 'total_pages': 9}, page_content='Bitcoin: A Peer-to-Peer Electronic Cash System\\nSatoshi Nakamoto\\nsatoshin@gmx.com\\nwww.bitcoin.org\\nAbstract.  A purely peer-to-peer version of  electronic cash would allow online  \\npayments to be sent directly from one party to another without going through a'),\n",
       " Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin (1).pdf', 'total_pages': 9}, page_content='Bitcoin: A Peer-to-Peer Electronic Cash System\\nSatoshi Nakamoto\\nsatoshin@gmx.com\\nwww.bitcoin.org\\nAbstract.  A purely peer-to-peer version of  electronic cash would allow online  \\npayments to be sent directly from one party to another without going through a'),\n",
       " Document(metadata={'creationdate': '2009-03-24T11:33:15-06:00', 'creator': 'Writer', 'page': 0, 'page_label': '1', 'producer': 'OpenOffice.org 2.4', 'source': 'docs\\\\bitcoin_whitepaper.pdf', 'total_pages': 9}, page_content='Bitcoin: A Peer-to-Peer Electronic Cash System\\nSatoshi Nakamoto\\nsatoshin@gmx.com\\nwww.bitcoin.org\\nAbstract.  A purely peer-to-peer version of  electronic cash would allow online  \\npayments to be sent directly from one party to another without going through a')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm_local, retriever, contextualize_q_prompt\n",
    ")\n",
    "history_aware_retriever.invoke({\"input\":\"How does it solve the problem of double spending?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0d20628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an intelligent assistant specialized in analyzing cryptocurrency whitepapers.\\n\"\n",
    "     \"You must answer strictly and only based on the provided context inserted below.\\n\"\n",
    "     \"Do not use any external knowledge, prior memory, or assumptions.\\n\"\n",
    "     \"If multiple relevant parts exist, combine them concisely and logically.\\n\"\n",
    "     \"If the question asks for a purpose, goal, or reason, prioritize explaining the *why* before the *how*.\\n\"\n",
    "     \"Think carefully and reason step-by-step if necessary, but always stay grounded in the provided context.\\n\"\n",
    "     \"If the answer cannot be clearly found in the context, you must respond exactly with:\\n\"\n",
    "     \"'The information is not available in the document.'\\n\"\n",
    "     \"You are strictly prohibited from guessing, assuming, completing, or inventing missing information.\\n\"\n",
    "     \"If possible, reference the page number or section from which the answer is derived.\\n\"\n",
    "     \"Do not generate academic references, bibliography entries, or external citations unless explicitly instructed.\\n\"\n",
    "     \"Only cite document sections if they are clearly included in the provided context.\"\n",
    "    ),\n",
    "    (\"system\", \"Context: {context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm_local, qa_prompt)\n",
    "rag_chain_final = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aee1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "DB_NAME = \"rag_app.db\"\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn\n",
    "\n",
    "def create_application_logs():\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    session_id TEXT,\n",
    "    user_query TEXT,\n",
    "    gpt_response TEXT,\n",
    "    model TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "    conn.close()\n",
    "\n",
    "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
    "                 (session_id, user_query, gpt_response, model))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {\"role\": \"human\", \"content\": row['user_query']},\n",
    "            {\"role\": \"ai\", \"content\": row['gpt_response']}\n",
    "        ])\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "# Initialize the database\n",
    "create_application_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51895427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, it seems that the original idea was to have a centralized minting process where coins must be returned to the mint after each transaction. However, this solution is problematic because it relies on a central authority.\n",
      "\n",
      "The information is not available in the document regarding how Bitcoin prevents double-spending without relying on a central authority, as this concept seems to be specific to the original idea and not directly related to Bitcoin's actual implementation.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "user_question = \"How does Bitcoin prevent double-spending without relying on a central authority?\"\n",
    "\n",
    "chat_history = get_chat_history(session_id)\n",
    "\n",
    "final_response = rag_chain_final.invoke({\n",
    "    \"input\": user_question,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "\n",
    "\n",
    "print(final_response['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 No answer found in document. Triggering web search agent...\n",
      "USER (hardcoded): Who are the founders and co founders of etherium ?\n",
      "\n",
      "GENERATING SEARCH QUERY.\n",
      "EXA Search Results: 8 results found.\n",
      "4\n",
      "✅ First 500 chars of scraped text:\n",
      "**The Uncanny Mind That Built Ethereum**\n",
      "\n",
      "## Vitalik Buterin invented the world’s hottest new cryptocurrency and inspired a movement — before he’d turned 20.\n",
      "\n",
      "--\n",
      "\n",
      "I** met Vitalik Buterin** for the first time in Miami, during a Bitcoin conference in 2014. I had been invited by a Bitcoiner I knew in New York to stay at a beach house with a team of developers who were working on the next big thing, a technology called Ethereum. I was told it would blow Bitcoin out of the water.\n",
      "\n",
      "Buterin and about a...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Start a session\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "# User input\n",
    "user_question = \"Who are the founders and co founders of etherium ?\"\n",
    "\n",
    "# Load past messages if any\n",
    "chat_history = get_chat_history(session_id)\n",
    "\n",
    "# Step 1: Try RAG\n",
    "final_response = rag_chain_final.invoke({\n",
    "    \"input\": user_question,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "\n",
    "# Step 2: Check if fallback is needed\n",
    "if \"The information is not available in the document.\" in final_response['answer']:\n",
    "    print(\"\\n🧠 No answer found in document. Triggering web search agent...\")\n",
    "    main(user_question)  # 🔁 Fallback to real-time web search\n",
    "else:\n",
    "    print(\"\\n📄 RAG Answer:\")\n",
    "    print(final_response['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eff3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
