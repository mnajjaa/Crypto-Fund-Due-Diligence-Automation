{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f9160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q sentence-transformers scikit-learn pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210c61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ce2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filepath):\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    documents = loader.load()\n",
    "    return \" \".join(doc.page_content for doc in documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3154af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load the two whitepapers\n",
    "reference_path = \"docs/bitcoin (1).pdf\"\n",
    "target_path = \"docs/MyCoin.pdf\"  # <-- change this to your file name\n",
    "\n",
    "reference_text = extract_text_from_pdf(reference_path)\n",
    "target_text = extract_text_from_pdf(target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a51a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Checking: MyCoin.pdf\n",
      "üîç Similarity with avalanche_whitepaper.pdf: 0.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity with bitcoin_whitepaper.pdf: 0.8752\n",
      "üö© High similarity detected with bitcoin_whitepaper.pdf ‚Äî possible plagiarism!\n",
      "üîç Similarity with cardano_whitepaper.pdf: 0.1215\n",
      "üîç Similarity with ethereum_whitepaper.pdf: 0.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity with litecoin_whitepaper.pdf: 0.5029\n",
      "üîç Similarity with polkadot_whitepaper.pdf: 0.1215\n",
      "üîç Similarity with solana-whitepaper.pdf: 0.2716\n",
      "‚ùå MyCoin.pdf is REJECTED due to high plagiarism risk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "docs_folder = \"projects\"\n",
    "references_folder = \"references\"\n",
    "\n",
    "# Load model once\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Find all user-uploaded documents\n",
    "uploaded_docs = [os.path.join(docs_folder, f) for f in os.listdir(docs_folder) if f.endswith('.pdf')]\n",
    "reference_docs = [os.path.join(references_folder, f) for f in os.listdir(references_folder) if f.endswith('.pdf')]\n",
    "\n",
    "# Loop through each uploaded whitepaper\n",
    "for upload_path in uploaded_docs:\n",
    "    print(f\"\\nüßæ Checking: {os.path.basename(upload_path)}\")\n",
    "\n",
    "    uploaded_text = extract_text_from_pdf(upload_path)\n",
    "    uploaded_embed = model.encode([uploaded_text])[0]\n",
    "\n",
    "    flagged = False\n",
    "\n",
    "    for ref_path in reference_docs:\n",
    "        ref_text = extract_text_from_pdf(ref_path)\n",
    "        ref_embed = model.encode([ref_text])[0]\n",
    "\n",
    "        similarity = cosine_similarity([uploaded_embed], [ref_embed])[0][0]\n",
    "        print(f\"üîç Similarity with {os.path.basename(ref_path)}: {similarity:.4f}\")\n",
    "\n",
    "        if similarity > 0.85:\n",
    "            print(f\"üö© High similarity detected with {os.path.basename(ref_path)} ‚Äî possible plagiarism!\")\n",
    "            flagged = True\n",
    "\n",
    "    if flagged:\n",
    "        print(f\"‚ùå {os.path.basename(upload_path)} is REJECTED due to high plagiarism risk.\\n\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {os.path.basename(upload_path)} is CLEAN ‚Äî ready for RAG ingestion.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30114376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Checking: bitcoin_whitepaper.pdf\n",
      "üîç Similarity with avalanche_whitepaper.pdf: 0.4024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity with bitcoin_whitepaper.pdf: 1.0000\n",
      "üîç Similarity with cardano_whitepaper.pdf: 0.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity with ethereum_whitepaper.pdf: 0.4696\n",
      "üîç Similarity with litecoin_whitepaper.pdf: 0.4771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity with polkadot_whitepaper.pdf: 0.1447\n",
      "üîç Similarity with solana-whitepaper.pdf: 0.2529\n",
      "‚ùå bitcoin_whitepaper.pdf is REJECTED due to high plagiarism risk.\n",
      "\n",
      "üìÑ Report saved at: outputs\\bitcoin_whitepaper_plagiarism_report.json\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "docs_folder = \"docs\"\n",
    "references_folder = \"references\"\n",
    "outputs_folder = \"outputs\"\n",
    "\n",
    "# Create outputs folder if missing\n",
    "os.makedirs(outputs_folder, exist_ok=True)\n",
    "\n",
    "# Load model once\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# List uploaded and reference files\n",
    "uploaded_docs = [os.path.join(docs_folder, f) for f in os.listdir(docs_folder) if f.endswith('.pdf')]\n",
    "reference_docs = [os.path.join(references_folder, f) for f in os.listdir(references_folder) if f.endswith('.pdf')]\n",
    "\n",
    "# Check each uploaded whitepaper\n",
    "for upload_path in uploaded_docs:\n",
    "    print(f\"\\nüßæ Checking: {os.path.basename(upload_path)}\")\n",
    "    \n",
    "    report = {\n",
    "        \"project_file\": os.path.basename(upload_path),\n",
    "        \"comparisons\": [],\n",
    "        \"overall_result\": \"\"\n",
    "    }\n",
    "    \n",
    "    uploaded_text = extract_text_from_pdf(upload_path)\n",
    "    uploaded_embed = model.encode([uploaded_text])[0]\n",
    "    \n",
    "    flagged = False\n",
    "\n",
    "    for ref_path in reference_docs:\n",
    "        ref_text = extract_text_from_pdf(ref_path)\n",
    "        ref_embed = model.encode([ref_text])[0]\n",
    "        \n",
    "        similarity = cosine_similarity([uploaded_embed], [ref_embed])[0][0]\n",
    "        print(f\"üîç Similarity with {os.path.basename(ref_path)}: {similarity:.4f}\")\n",
    "\n",
    "        report[\"comparisons\"].append({\n",
    "            \"reference_file\": os.path.basename(ref_path),\n",
    "            \"similarity_score\": round(float(similarity), 4)\n",
    "        })\n",
    "\n",
    "        if similarity > 0.85:\n",
    "            flagged = True\n",
    "\n",
    "    if flagged:\n",
    "        print(f\"‚ùå {os.path.basename(upload_path)} is REJECTED due to high plagiarism risk.\\n\")\n",
    "        report[\"overall_result\"] = \"Rejected due to high similarity.\"\n",
    "    else:\n",
    "        print(f\"‚úÖ {os.path.basename(upload_path)} is CLEAN ‚Äî ready for RAG ingestion.\\n\")\n",
    "        report[\"overall_result\"] = \"Accepted. No high similarity detected.\"\n",
    "\n",
    "    # Save the report to outputs/\n",
    "    output_path = os.path.join(outputs_folder, f\"{os.path.splitext(os.path.basename(upload_path))[0]}_plagiarism_report.json\")\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    print(f\"üìÑ Report saved at: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
